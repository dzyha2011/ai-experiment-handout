# SVMæ•™å­¦ç½‘é¡µåç«¯æœåŠ¡å™¨
from flask import Flask, request, jsonify, send_from_directory
import numpy as np
import io
import sys
import base64
from contextlib import redirect_stdout, redirect_stderr
import traceback

# å¯¼å…¥æ‰€éœ€çš„æœºå™¨å­¦ä¹ åº“
from sklearn.datasets import load_breast_cancer, make_moons, make_classification, fetch_20newsgroups
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer

# é…ç½®matplotlibä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt

app = Flask(__name__, static_folder='.', static_url_path='')

# ä¸ºæ¯ä¸ªé€‰é¡¹å¡ç»´æŠ¤ç‹¬ç«‹çš„æ‰§è¡Œç¯å¢ƒ
tab_environments = {}

# ç®€å•çš„CORSå¤„ç†
@app.after_request
def after_request(response):
    response.headers.add('Access-Control-Allow-Origin', '*')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')
    response.headers.add('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE,OPTIONS')
    return response

def get_tab_environment(tab_id):
    """è·å–æˆ–åˆ›å»ºé€‰é¡¹å¡çš„æ‰§è¡Œç¯å¢ƒ"""
    if tab_id not in tab_environments:
        # åˆ›å»ºè‡ªå®šä¹‰çš„pltå¯¹è±¡ï¼Œæ”¯æŒå›¾è¡¨ç”Ÿæˆå’Œæ•°æ®åˆ†å¸ƒæ˜¾ç¤º
        class SafePlot:
            def __init__(self):
                self.figure_count = 0
                
            def __getattr__(self, name):
                attr = getattr(plt, name)
                if name == 'show':
                    return self._show_plot
                return attr
                
            def _show_plot(self, *args, **kwargs):
                self.figure_count += 1
                # è·å–å½“å‰å›¾è¡¨ä¿¡æ¯
                fig = plt.gcf()
                if fig.get_axes():
                    ax = fig.get_axes()[0]
                    title = ax.get_title() if ax.get_title() else f"å›¾è¡¨ {self.figure_count}"
                    print(f"ğŸ“Š {title} å·²ç”Ÿæˆ")
                    
                    # æ˜¾ç¤ºå›¾è¡¨çš„åŸºæœ¬ä¿¡æ¯
                    if hasattr(ax, 'collections') and ax.collections:
                        # æ•£ç‚¹å›¾
                        for i, collection in enumerate(ax.collections):
                            if hasattr(collection, '_offsets') and len(collection._offsets) > 0:
                                print(f"  - æ•°æ®ç‚¹æ•°é‡: {len(collection._offsets)}")
                    
                    # æ˜¾ç¤ºåæ ‡è½´æ ‡ç­¾
                    xlabel = ax.get_xlabel()
                    ylabel = ax.get_ylabel()
                    if xlabel:
                        print(f"  - Xè½´: {xlabel}")
                    if ylabel:
                        print(f"  - Yè½´: {ylabel}")
                        
                    # æ˜¾ç¤ºå›¾ä¾‹ä¿¡æ¯
                    legend = ax.get_legend()
                    if legend:
                        labels = [t.get_text() for t in legend.get_texts()]
                        print(f"  - ç±»åˆ«: {', '.join(labels)}")
                        
                else:
                    print(f"ğŸ“Š å›¾è¡¨ {self.figure_count} å·²ç”Ÿæˆï¼ˆåœ¨æœåŠ¡å™¨ç¯å¢ƒä¸­ä¸æ˜¾ç¤ºäº¤äº’å¼å›¾è¡¨ï¼‰")
                
                # æ¸…é™¤å½“å‰å›¾è¡¨ä»¥é¿å…é‡å 
                plt.clf()
        
        tab_environments[tab_id] = {
            '__builtins__': __builtins__,
            'np': np,
            'matplotlib': matplotlib,
            'plt': SafePlot(),
            'load_breast_cancer': load_breast_cancer,
            'make_moons': make_moons,
            'make_classification': make_classification,
            'fetch_20newsgroups': fetch_20newsgroups,
            'train_test_split': train_test_split,
            'GridSearchCV': GridSearchCV,
            'SVC': SVC,
            'accuracy_score': accuracy_score,
            'classification_report': classification_report,
            'StandardScaler': StandardScaler,
            'TfidfVectorizer': TfidfVectorizer
        }
    return tab_environments[tab_id]

@app.route('/run_code', methods=['POST'])
def run_code():
    try:
        data = request.get_json()
        code_id = data.get('code_id', '')
        code = data.get('code', '')
        tab_id = data.get('tab_id', 'default')  # è·å–é€‰é¡¹å¡ID
        reset_env = data.get('reset_env', False)  # æ˜¯å¦é‡ç½®ç¯å¢ƒ
        
        # å¦‚æœéœ€è¦é‡ç½®ç¯å¢ƒï¼Œæ¸…é™¤è¯¥é€‰é¡¹å¡çš„ç¯å¢ƒ
        if reset_env and tab_id in tab_environments:
            del tab_environments[tab_id]
        
        # è·å–é€‰é¡¹å¡ç‰¹å®šçš„æ‰§è¡Œç¯å¢ƒ
        exec_globals = get_tab_environment(tab_id)
        
        # æ•è·è¾“å‡º
        output_buffer = io.StringIO()
        error_buffer = io.StringIO()
        
        # æ·»åŠ printå‡½æ•°åˆ°ç¯å¢ƒä¸­
        exec_globals['print'] = lambda *args, **kwargs: print(*args, **kwargs, file=output_buffer)
        
        try:
            with redirect_stdout(output_buffer), redirect_stderr(error_buffer):
                exec(code, exec_globals)
            
            output = output_buffer.getvalue()
            error = error_buffer.getvalue()
            
            if error:
                return jsonify({
                    'success': False,
                    'output': output,
                    'error': error
                })
            else:
                return jsonify({
                    'success': True,
                    'output': output,
                    'error': ''
                })
                
        except Exception as e:
            error_msg = f"æ‰§è¡Œé”™è¯¯: {str(e)}\n{traceback.format_exc()}"
            return jsonify({
                'success': False,
                'output': output_buffer.getvalue(),
                'error': error_msg
            })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'output': '',
            'error': f"æœåŠ¡å™¨é”™è¯¯: {str(e)}"
        })

@app.route('/reset_tab_env', methods=['POST'])
def reset_tab_env():
    """é‡ç½®æŒ‡å®šé€‰é¡¹å¡çš„æ‰§è¡Œç¯å¢ƒ"""
    try:
        data = request.get_json()
        tab_id = data.get('tab_id', 'default')
        
        if tab_id in tab_environments:
            del tab_environments[tab_id]
            
        return jsonify({
            'success': True,
            'message': f'é€‰é¡¹å¡ {tab_id} çš„æ‰§è¡Œç¯å¢ƒå·²é‡ç½®'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f"é‡ç½®ç¯å¢ƒé”™è¯¯: {str(e)}"
        })

@app.route('/run_svm_demo', methods=['POST'])
def run_svm_demo():
    """è¿è¡Œç‰¹å®šçš„SVMæ¼”ç¤ºä»£ç """
    try:
        data = request.get_json()
        demo_type = data.get('demo_type', '')
        params = data.get('params', {})
        
        output_buffer = io.StringIO()
        
        if demo_type == 'linear':
            result = run_linear_svm_demo(params, output_buffer)
        elif demo_type == 'nonlinear':
            result = run_nonlinear_svm_demo(params, output_buffer)
        elif demo_type == 'optimization':
            result = run_optimization_demo(params, output_buffer)
        elif demo_type == 'spam':
            result = run_spam_demo(params, output_buffer)
        else:
            return jsonify({
                'success': False,
                'output': '',
                'error': f'æœªçŸ¥çš„æ¼”ç¤ºç±»å‹: {demo_type}'
            })
        
        return jsonify({
            'success': True,
            'output': output_buffer.getvalue(),
            'result': result
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'output': '',
            'error': f"æ¼”ç¤ºæ‰§è¡Œé”™è¯¯: {str(e)}\n{traceback.format_exc()}"
        })

def run_linear_svm_demo(params, output_buffer):
    """è¿è¡Œçº¿æ€§SVMæ¼”ç¤º"""
    C = float(params.get('C', 1.0))
    
    print(f"=== çº¿æ€§SVMæ¼”ç¤º (C={C}) ===", file=output_buffer)
    
    # åŠ è½½ä¹³è…ºç™Œæ•°æ®é›†
    data = load_breast_cancer()
    X, y = data.data, data.target
    
    # æ˜¾ç¤ºæ•°æ®é›†åˆ†å¸ƒä¿¡æ¯
    print(f"\nğŸ“Š æ•°æ®é›†åˆ†å¸ƒåˆ†æ:", file=output_buffer)
    print(f"æ•°æ®é›†å½¢çŠ¶: {X.shape}", file=output_buffer)
    print(f"ç‰¹å¾æ•°é‡: {X.shape[1]}", file=output_buffer)
    print(f"æ ·æœ¬æ€»æ•°: {X.shape[0]}", file=output_buffer)
    print(f"è‰¯æ€§æ ·æœ¬æ•°: {np.sum(y == 1)} ({np.sum(y == 1)/len(y)*100:.1f}%)", file=output_buffer)
    print(f"æ¶æ€§æ ·æœ¬æ•°: {np.sum(y == 0)} ({np.sum(y == 0)/len(y)*100:.1f}%)", file=output_buffer)
    
    # æ˜¾ç¤ºç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“ˆ ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯:", file=output_buffer)
    print(f"ç‰¹å¾å‡å€¼èŒƒå›´: [{X.mean(axis=0).min():.2f}, {X.mean(axis=0).max():.2f}]", file=output_buffer)
    print(f"ç‰¹å¾æ ‡å‡†å·®èŒƒå›´: [{X.std(axis=0).min():.2f}, {X.std(axis=0).max():.2f}]", file=output_buffer)
    
    # å¯è§†åŒ–å‰ä¸¤ä¸ªä¸»è¦ç‰¹å¾çš„åˆ†å¸ƒ
    plt.figure(figsize=(12, 4))
    
    # å­å›¾1: å‰ä¸¤ä¸ªç‰¹å¾çš„æ•£ç‚¹å›¾
    plt.subplot(1, 3, 1)
    colors = ['red' if label == 0 else 'blue' for label in y]
    plt.scatter(X[:, 0], X[:, 1], c=colors, alpha=0.6)
    plt.xlabel(data.feature_names[0])
    plt.ylabel(data.feature_names[1])
    plt.title('åŸå§‹æ•°æ®åˆ†å¸ƒ\n(å‰ä¸¤ä¸ªç‰¹å¾)')
    plt.legend(['æ¶æ€§', 'è‰¯æ€§'])
    
    # å­å›¾2: ç‰¹å¾å‡å€¼åˆ†å¸ƒ
    plt.subplot(1, 3, 2)
    mean_features_0 = X[y == 0].mean(axis=0)
    mean_features_1 = X[y == 1].mean(axis=0)
    feature_indices = range(len(data.feature_names[:10]))  # æ˜¾ç¤ºå‰10ä¸ªç‰¹å¾
    plt.bar([i - 0.2 for i in feature_indices], mean_features_0[:10], width=0.4, label='æ¶æ€§', color='red', alpha=0.7)
    plt.bar([i + 0.2 for i in feature_indices], mean_features_1[:10], width=0.4, label='è‰¯æ€§', color='blue', alpha=0.7)
    plt.xlabel('ç‰¹å¾ç´¢å¼•')
    plt.ylabel('ç‰¹å¾å‡å€¼')
    plt.title('å„ç±»åˆ«ç‰¹å¾å‡å€¼å¯¹æ¯”\n(å‰10ä¸ªç‰¹å¾)')
    plt.legend()
    plt.xticks(feature_indices)
    
    # å­å›¾3: ç±»åˆ«åˆ†å¸ƒé¥¼å›¾
    plt.subplot(1, 3, 3)
    labels = ['æ¶æ€§', 'è‰¯æ€§']
    sizes = [np.sum(y == 0), np.sum(y == 1)]
    colors = ['red', 'blue']
    plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', alpha=0.7)
    plt.title('ç±»åˆ«åˆ†å¸ƒ')
    
    plt.tight_layout()
    plt.show()
    
    # åˆ’åˆ†æ•°æ®é›†
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    print(f"\nğŸ”„ æ•°æ®åˆ’åˆ†:", file=output_buffer)
    print(f"è®­ç»ƒé›†å¤§å°: {X_train.shape[0]}", file=output_buffer)
    print(f"æµ‹è¯•é›†å¤§å°: {X_test.shape[0]}", file=output_buffer)
    print(f"è®­ç»ƒé›†ä¸­è‰¯æ€§æ ·æœ¬: {np.sum(y_train == 1)} ({np.sum(y_train == 1)/len(y_train)*100:.1f}%)", file=output_buffer)
    print(f"æµ‹è¯•é›†ä¸­è‰¯æ€§æ ·æœ¬: {np.sum(y_test == 1)} ({np.sum(y_test == 1)/len(y_test)*100:.1f}%)", file=output_buffer)
    
    # æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # è®­ç»ƒæ¨¡å‹
    svm_linear = SVC(kernel='linear', C=C, random_state=42)
    svm_linear.fit(X_train_scaled, y_train)
    
    # é¢„æµ‹å’Œè¯„ä¼°
    y_pred = svm_linear.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\nğŸ¯ æ¨¡å‹æ€§èƒ½:", file=output_buffer)
    print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f}", file=output_buffer)
    print(f"æ”¯æŒå‘é‡æ•°é‡: {len(svm_linear.support_)}", file=output_buffer)
    
    # æ ¹æ®Cå€¼ç»™å‡ºå»ºè®®
    if C < 0.1:
        print("ğŸ’¡ æç¤º: Cå€¼è¾ƒå°ï¼Œæ¨¡å‹å¯èƒ½æ¬ æ‹Ÿåˆ", file=output_buffer)
    elif C > 10:
        print("âš ï¸ è­¦å‘Š: Cå€¼è¾ƒå¤§ï¼Œæ¨¡å‹å¯èƒ½è¿‡æ‹Ÿåˆ", file=output_buffer)
    else:
        print("âœ… Cå€¼é€‚ä¸­ï¼Œæ¨¡å‹è¡¨ç°è‰¯å¥½", file=output_buffer)
    
    return {
        'accuracy': accuracy,
        'support_vectors': len(svm_linear.support_),
        'C': C
    }

def run_nonlinear_svm_demo(params, output_buffer):
    """è¿è¡Œéçº¿æ€§SVMæ¼”ç¤º"""
    gamma_param = params.get('gamma', 1.0)
    # å¤„ç†gammaå‚æ•°ï¼Œå¦‚æœæ˜¯å­—ç¬¦ä¸²'scale'æˆ–'auto'åˆ™ä¿æŒåŸæ ·ï¼Œå¦åˆ™è½¬æ¢ä¸ºfloat
    if isinstance(gamma_param, str) and gamma_param in ['scale', 'auto']:
        gamma = gamma_param
    else:
        gamma = float(gamma_param)
    C = float(params.get('C', 1.0))
    
    print(f"=== éçº¿æ€§SVMæ¼”ç¤º (C={C}, gamma={gamma}) ===", file=output_buffer)
    
    # ç”Ÿæˆéçº¿æ€§æ•°æ®
    X, y = make_moons(n_samples=200, noise=0.1, random_state=42)
    
    # æ˜¾ç¤ºæ•°æ®é›†åˆ†å¸ƒä¿¡æ¯
    print(f"\nğŸ“Š æ•°æ®é›†åˆ†å¸ƒåˆ†æ:", file=output_buffer)
    print(f"æ•°æ®é›†å½¢çŠ¶: {X.shape}", file=output_buffer)
    print(f"ç‰¹å¾æ•°é‡: {X.shape[1]}", file=output_buffer)
    print(f"æ ·æœ¬æ€»æ•°: {X.shape[0]}", file=output_buffer)
    print(f"ç±»åˆ«0æ ·æœ¬æ•°: {np.sum(y == 0)} ({np.sum(y == 0)/len(y)*100:.1f}%)", file=output_buffer)
    print(f"ç±»åˆ«1æ ·æœ¬æ•°: {np.sum(y == 1)} ({np.sum(y == 1)/len(y)*100:.1f}%)", file=output_buffer)
    
    # æ˜¾ç¤ºç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“ˆ ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯:", file=output_buffer)
    print(f"X1ç‰¹å¾èŒƒå›´: [{X[:, 0].min():.2f}, {X[:, 0].max():.2f}]", file=output_buffer)
    print(f"X2ç‰¹å¾èŒƒå›´: [{X[:, 1].min():.2f}, {X[:, 1].max():.2f}]", file=output_buffer)
    print(f"X1ç‰¹å¾å‡å€¼: {X[:, 0].mean():.2f} Â± {X[:, 0].std():.2f}", file=output_buffer)
    print(f"X2ç‰¹å¾å‡å€¼: {X[:, 1].mean():.2f} Â± {X[:, 1].std():.2f}", file=output_buffer)
    
    # å¯è§†åŒ–æ•°æ®åˆ†å¸ƒ
    plt.figure(figsize=(15, 5))
    
    # å­å›¾1: åŸå§‹æ•°æ®æ•£ç‚¹å›¾
    plt.subplot(1, 3, 1)
    colors = ['red', 'blue']
    for i in range(2):
        mask = y == i
        plt.scatter(X[mask, 0], X[mask, 1], c=colors[i], label=f'ç±»åˆ« {i}', alpha=0.7, s=50)
    plt.xlabel('ç‰¹å¾ X1')
    plt.ylabel('ç‰¹å¾ X2')
    plt.title('æœˆç‰™å½¢æ•°æ®åˆ†å¸ƒ\n(éçº¿æ€§å¯åˆ†)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # å­å›¾2: ç‰¹å¾åˆ†å¸ƒç›´æ–¹å›¾
    plt.subplot(1, 3, 2)
    plt.hist(X[y == 0, 0], bins=15, alpha=0.7, color='red', label='ç±»åˆ«0 - X1')
    plt.hist(X[y == 1, 0], bins=15, alpha=0.7, color='blue', label='ç±»åˆ«1 - X1')
    plt.xlabel('ç‰¹å¾ X1 å€¼')
    plt.ylabel('é¢‘æ¬¡')
    plt.title('X1ç‰¹å¾åˆ†å¸ƒ')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # å­å›¾3: ç‰¹å¾åˆ†å¸ƒç›´æ–¹å›¾
    plt.subplot(1, 3, 3)
    plt.hist(X[y == 0, 1], bins=15, alpha=0.7, color='red', label='ç±»åˆ«0 - X2')
    plt.hist(X[y == 1, 1], bins=15, alpha=0.7, color='blue', label='ç±»åˆ«1 - X2')
    plt.xlabel('ç‰¹å¾ X2 å€¼')
    plt.ylabel('é¢‘æ¬¡')
    plt.title('X2ç‰¹å¾åˆ†å¸ƒ')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # åˆ’åˆ†æ•°æ®é›†
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    print(f"\nğŸ”„ æ•°æ®åˆ’åˆ†:", file=output_buffer)
    print(f"è®­ç»ƒé›†å¤§å°: {X_train.shape[0]}", file=output_buffer)
    print(f"æµ‹è¯•é›†å¤§å°: {X_test.shape[0]}", file=output_buffer)
    print(f"è®­ç»ƒé›†ä¸­ç±»åˆ«1æ ·æœ¬: {np.sum(y_train == 1)} ({np.sum(y_train == 1)/len(y_train)*100:.1f}%)", file=output_buffer)
    print(f"æµ‹è¯•é›†ä¸­ç±»åˆ«1æ ·æœ¬: {np.sum(y_test == 1)} ({np.sum(y_test == 1)/len(y_test)*100:.1f}%)", file=output_buffer)
    
    # è®­ç»ƒRBFæ ¸SVM
    svm_rbf = SVC(kernel='rbf', C=C, gamma=gamma, random_state=42)
    svm_rbf.fit(X_train, y_train)
    
    # é¢„æµ‹å’Œè¯„ä¼°
    y_pred = svm_rbf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\nğŸ¯ æ¨¡å‹æ€§èƒ½:", file=output_buffer)
    print(f"RBFæ ¸å‡†ç¡®ç‡: {accuracy:.4f}", file=output_buffer)
    print(f"æ”¯æŒå‘é‡æ•°é‡: {len(svm_rbf.support_)}", file=output_buffer)
    
    # å‚æ•°å»ºè®®
    if gamma < 0.01:
        print("ğŸ’¡ æç¤º: gammaå€¼è¾ƒå°ï¼Œå†³ç­–è¾¹ç•Œè¾ƒå¹³æ»‘", file=output_buffer)
    elif gamma > 10:
        print("âš ï¸ è­¦å‘Š: gammaå€¼è¾ƒå¤§ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆ", file=output_buffer)
    else:
        print("âœ… gammaå€¼é€‚ä¸­", file=output_buffer)
    
    return {
        'accuracy': accuracy,
        'support_vectors': len(svm_rbf.support_),
        'C': C,
        'gamma': gamma
    }

def run_optimization_demo(params, output_buffer):
    """è¿è¡Œå‚æ•°ä¼˜åŒ–æ¼”ç¤º"""
    print("=== å‚æ•°ä¼˜åŒ–æ¼”ç¤º ===", file=output_buffer)
    
    # ç”Ÿæˆåˆ†ç±»æ•°æ®
    X, y = make_classification(n_samples=300, n_features=10, n_classes=2, random_state=42)
    
    # æ˜¾ç¤ºæ•°æ®é›†åˆ†å¸ƒä¿¡æ¯
    print(f"\nğŸ“Š æ•°æ®é›†åˆ†å¸ƒåˆ†æ:", file=output_buffer)
    print(f"æ•°æ®é›†å½¢çŠ¶: {X.shape}", file=output_buffer)
    print(f"ç‰¹å¾æ•°é‡: {X.shape[1]}", file=output_buffer)
    print(f"æ ·æœ¬æ€»æ•°: {X.shape[0]}", file=output_buffer)
    print(f"ç±»åˆ«0æ ·æœ¬æ•°: {np.sum(y == 0)} ({np.sum(y == 0)/len(y)*100:.1f}%)", file=output_buffer)
    print(f"ç±»åˆ«1æ ·æœ¬æ•°: {np.sum(y == 1)} ({np.sum(y == 1)/len(y)*100:.1f}%)", file=output_buffer)
    
    # æ˜¾ç¤ºç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“ˆ ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯:", file=output_buffer)
    print(f"ç‰¹å¾å‡å€¼èŒƒå›´: [{X.mean(axis=0).min():.2f}, {X.mean(axis=0).max():.2f}]", file=output_buffer)
    print(f"ç‰¹å¾æ ‡å‡†å·®èŒƒå›´: [{X.std(axis=0).min():.2f}, {X.std(axis=0).max():.2f}]", file=output_buffer)
    
    # å¯è§†åŒ–æ•°æ®åˆ†å¸ƒ
    plt.figure(figsize=(15, 5))
    
    # å­å›¾1: å‰ä¸¤ä¸ªç‰¹å¾çš„æ•£ç‚¹å›¾
    plt.subplot(1, 3, 1)
    colors = ['red', 'blue']
    for i in range(2):
        mask = y == i
        plt.scatter(X[mask, 0], X[mask, 1], c=colors[i], label=f'ç±»åˆ« {i}', alpha=0.7, s=50)
    plt.xlabel('ç‰¹å¾ 1')
    plt.ylabel('ç‰¹å¾ 2')
    plt.title('åˆæˆæ•°æ®åˆ†å¸ƒ\n(å‰ä¸¤ä¸ªç‰¹å¾)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # å­å›¾2: ç‰¹å¾é‡è¦æ€§ï¼ˆæ–¹å·®ï¼‰
    plt.subplot(1, 3, 2)
    feature_vars = X.var(axis=0)
    plt.bar(range(len(feature_vars)), feature_vars, color='skyblue', alpha=0.7)
    plt.xlabel('ç‰¹å¾ç´¢å¼•')
    plt.ylabel('æ–¹å·®')
    plt.title('å„ç‰¹å¾æ–¹å·®åˆ†å¸ƒ')
    plt.grid(True, alpha=0.3)
    
    # å­å›¾3: ç±»åˆ«é—´ç‰¹å¾å‡å€¼å·®å¼‚
    plt.subplot(1, 3, 3)
    mean_diff = np.abs(X[y == 0].mean(axis=0) - X[y == 1].mean(axis=0))
    plt.bar(range(len(mean_diff)), mean_diff, color='lightcoral', alpha=0.7)
    plt.xlabel('ç‰¹å¾ç´¢å¼•')
    plt.ylabel('ç±»åˆ«é—´å‡å€¼å·®å¼‚')
    plt.title('ç±»åˆ«é—´ç‰¹å¾å·®å¼‚')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # åˆ’åˆ†æ•°æ®é›†
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    print(f"\nğŸ”„ æ•°æ®åˆ’åˆ†:", file=output_buffer)
    print(f"è®­ç»ƒé›†å¤§å°: {X_train.shape[0]}", file=output_buffer)
    print(f"æµ‹è¯•é›†å¤§å°: {X_test.shape[0]}", file=output_buffer)
    print(f"è®­ç»ƒé›†ä¸­ç±»åˆ«1æ ·æœ¬: {np.sum(y_train == 1)} ({np.sum(y_train == 1)/len(y_train)*100:.1f}%)", file=output_buffer)
    print(f"æµ‹è¯•é›†ä¸­ç±»åˆ«1æ ·æœ¬: {np.sum(y_test == 1)} ({np.sum(y_test == 1)/len(y_test)*100:.1f}%)", file=output_buffer)
    
    # æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # ç½‘æ ¼æœç´¢
    param_grid = {
        'C': [0.1, 1, 10],
        'gamma': [0.01, 0.1, 1.0]
    }
    
    print(f"\nğŸ” å¼€å§‹ç½‘æ ¼æœç´¢...", file=output_buffer)
    grid_search = GridSearchCV(SVC(kernel='rbf', random_state=42), param_grid, cv=3, scoring='accuracy')
    grid_search.fit(X_train_scaled, y_train)
    
    # æµ‹è¯•æœ€ä½³æ¨¡å‹
    best_model = grid_search.best_estimator_
    test_accuracy = best_model.score(X_test_scaled, y_test)
    
    print(f"\nğŸ¯ ä¼˜åŒ–ç»“æœ:", file=output_buffer)
    print(f"ğŸ† æœ€ä½³å‚æ•°: C={grid_search.best_params_['C']}, gamma={grid_search.best_params_['gamma']}", file=output_buffer)
    print(f"ğŸ“Š æœ€ä½³äº¤å‰éªŒè¯å‡†ç¡®ç‡: {grid_search.best_score_:.4f}", file=output_buffer)
    print(f"ğŸ¯ æµ‹è¯•é›†å‡†ç¡®ç‡: {test_accuracy:.4f}", file=output_buffer)
    
    return {
        'best_params': grid_search.best_params_,
        'best_cv_score': grid_search.best_score_,
        'test_accuracy': test_accuracy
    }

def run_spam_demo(params, output_buffer):
    """è¿è¡Œåƒåœ¾é‚®ä»¶åˆ†ç±»æ¼”ç¤º"""
    kernel = params.get('kernel', 'rbf')
    C = float(params.get('C', 1.0))
    gamma_param = params.get('gamma', 'scale')
    # å¤„ç†gammaå‚æ•°ï¼Œå¦‚æœæ˜¯å­—ç¬¦ä¸²'scale'æˆ–'auto'åˆ™ä¿æŒåŸæ ·ï¼Œå¦åˆ™è½¬æ¢ä¸ºfloat
    if isinstance(gamma_param, str) and gamma_param in ['scale', 'auto']:
        gamma = gamma_param
    else:
        gamma = float(gamma_param)
    
    print(f"=== åƒåœ¾é‚®ä»¶åˆ†ç±»æ¼”ç¤º (kernel={kernel}, C={C}) ===", file=output_buffer)
    
    try:
        # åŠ è½½æ–°é—»ç»„æ•°æ®é›†
        categories = ['rec.sport.hockey', 'talk.politics.misc']
        newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, random_state=42)
        newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, random_state=42)
        
        # TF-IDFç‰¹å¾åŒ–
        vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')  # å‡å°‘ç‰¹å¾æ•°é‡ä»¥æé«˜é€Ÿåº¦
        X_train_tfidf = vectorizer.fit_transform(newsgroups_train.data)
        X_test_tfidf = vectorizer.transform(newsgroups_test.data)
        
        # è®­ç»ƒSVM
        svm_classifier = SVC(kernel=kernel, C=C, gamma=gamma, random_state=42)
        
        svm_classifier.fit(X_train_tfidf, newsgroups_train.target)
        
        # é¢„æµ‹
        y_pred = svm_classifier.predict(X_test_tfidf)
        accuracy = accuracy_score(newsgroups_test.target, y_pred)
        
        print(f"ğŸ“§ è®­ç»ƒé‚®ä»¶æ•°é‡: {len(newsgroups_train.data)}", file=output_buffer)
        print(f"ğŸ“§ æµ‹è¯•é‚®ä»¶æ•°é‡: {len(newsgroups_test.data)}", file=output_buffer)
        print(f"ğŸ”¤ ç‰¹å¾ç»´åº¦: {X_train_tfidf.shape[1]}", file=output_buffer)
        print(f"ğŸ“Š åˆ†ç±»å‡†ç¡®ç‡: {accuracy:.4f}", file=output_buffer)
        
        # è®¡ç®—å…¶ä»–æŒ‡æ ‡
        from sklearn.metrics import precision_score, recall_score, f1_score
        precision = precision_score(newsgroups_test.target, y_pred, average='weighted')
        recall = recall_score(newsgroups_test.target, y_pred, average='weighted')
        f1 = f1_score(newsgroups_test.target, y_pred, average='weighted')
        
        print(f"ğŸ“ˆ ç²¾ç¡®ç‡: {precision:.4f}", file=output_buffer)
        print(f"ğŸ“ˆ å¬å›ç‡: {recall:.4f}", file=output_buffer)
        print(f"ğŸ“ˆ F1åˆ†æ•°: {f1:.4f}", file=output_buffer)
        
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'kernel': kernel,
            'C': C
        }
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®: {str(e)}", file=output_buffer)
        # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        accuracy = 0.85 + (C - 1) * 0.05 + np.random.normal(0, 0.02)
        accuracy = max(0.7, min(0.99, accuracy))
        
        return {
            'accuracy': accuracy,
            'precision': accuracy + 0.01,
            'recall': accuracy - 0.01,
            'f1_score': accuracy,
            'kernel': kernel,
            'C': C
        }

@app.route('/')
def index():
    return send_from_directory('.', 'ç¬¬å…­ç«  æ”¯æŒå‘é‡æœºæ•™å­¦ç½‘é¡µ.html')

@app.route('/<path:filename>')
def serve_file(filename):
    return send_from_directory('.', filename)

@app.route('/static/<path:filename>')
def serve_static(filename):
    return send_from_directory('static', filename)

@app.route('/train_svm', methods=['POST'])
def train_svm():
    try:
        # è·å–å‚æ•°
        data = request.get_json()
        kernel = data.get('kernel', 'rbf')
        C = float(data.get('C', 1.0))
        gamma = float(data.get('gamma', 0.1))
        max_features = int(data.get('max_features', 5000))
        
        # åŠ è½½æ•°æ®
        categories = ['rec.sport.hockey', 'talk.politics.misc']
        newsgroups = fetch_20newsgroups(
            subset='all', 
            categories=categories, 
            remove=('headers', 'footers', 'quotes'), 
            random_state=42
        )
        X_text = newsgroups.data
        y = newsgroups.target
        
        # åˆ’åˆ†è®­ç»ƒé›†ä¸æµ‹è¯•é›†
        X_train_text, X_test_text, y_train, y_test = train_test_split(
            X_text, y, test_size=0.3, random_state=42
        )
        
        # TF-IDFç‰¹å¾å‘é‡åŒ–
        tfidf = TfidfVectorizer(max_features=max_features, stop_words='english')
        X_train_tfidf = tfidf.fit_transform(X_train_text)
        X_test_tfidf = tfidf.transform(X_test_text)
        
        # è®­ç»ƒSVMæ¨¡å‹
        if kernel == 'linear':
            svm_model = SVC(C=C, kernel='linear', random_state=42)
        elif kernel == 'poly':
            svm_model = SVC(C=C, kernel='poly', degree=3, random_state=42)
        else:  # rbf
            svm_model = SVC(C=C, gamma=gamma, kernel='rbf', random_state=42)
            
        svm_model.fit(X_train_tfidf, y_train)
        
        # è¯„ä¼°æ€§èƒ½
        y_pred_train = svm_model.predict(X_train_tfidf)
        y_pred_test = svm_model.predict(X_test_tfidf)
        
        train_accuracy = accuracy_score(y_train, y_pred_train)
        test_accuracy = accuracy_score(y_test, y_pred_test)
        
        # è·å–æ”¯æŒå‘é‡æ•°é‡
        n_support_vectors = len(svm_model.support_)
        
        # ç”Ÿæˆæ··æ·†çŸ©é˜µå›¾
        plt.figure(figsize=(8, 6))
        from sklearn.metrics import confusion_matrix
        cm = confusion_matrix(y_test, y_pred_test)
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        plt.imshow(cm, interpolation='nearest', cmap='Blues')
        plt.title(f'Confusion Matrix - {kernel.upper()} Kernel')
        plt.colorbar()
        
        # æ·»åŠ æ ‡ç­¾
        classes = ['Hockey', 'Politics']
        tick_marks = np.arange(len(classes))
        plt.xticks(tick_marks, classes)
        plt.yticks(tick_marks, classes)
        
        # æ·»åŠ æ•°å€¼
        thresh = cm.max() / 2.
        for i, j in np.ndindex(cm.shape):
            plt.text(j, i, format(cm[i, j], 'd'),
                    horizontalalignment="center",
                    color="white" if cm[i, j] > thresh else "black")
        
        plt.xlabel('Predicted')
        plt.ylabel('True')
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡åˆ°å†…å­˜
        img_buffer = io.BytesIO()
        plt.savefig(img_buffer, format='png', dpi=150, bbox_inches='tight')
        img_buffer.seek(0)
        img_base64 = base64.b64encode(img_buffer.getvalue()).decode()
        plt.close()
        
        # åˆ†ç±»æŠ¥å‘Š
        report = classification_report(y_test, y_pred_test, 
                                     target_names=['Hockey', 'Politics'], 
                                     output_dict=True)
        
        return jsonify({
            'success': True,
            'results': {
                'kernel': kernel,
                'C': C,
                'gamma': gamma if kernel == 'rbf' else None,
                'max_features': max_features,
                'train_accuracy': round(train_accuracy, 4),
                'test_accuracy': round(test_accuracy, 4),
                'n_support_vectors': n_support_vectors,
                'confusion_matrix_img': img_base64,
                'classification_report': report
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

if __name__ == '__main__':
    print("å¯åŠ¨SVMæ•™å­¦æœåŠ¡å™¨...")
    print("æœåŠ¡å™¨åœ°å€: http://localhost:5000")
    app.run(debug=True, host='127.0.0.1', port=5000)