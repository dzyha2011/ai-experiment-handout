#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
LLEå®éªŒè®²ä¹‰ä»£ç æµ‹è¯•æ–‡ä»¶
æµ‹è¯•æ‰€æœ‰ä»£ç ç‰‡æ®µæ˜¯å¦å¯ä»¥æ­£å¸¸è¿è¡Œ
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_swiss_roll, load_digits, fetch_olivetti_faces
from sklearn.manifold import LocallyLinearEmbedding
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from sklearn.decomposition import PCA
from mpl_toolkits.mplot3d import Axes3D
import time
import warnings
warnings.filterwarnings('ignore')

def test_swiss_roll_example():
    """æµ‹è¯•ç‘å£«å·æ•°æ®é›†é™ç»´å®éªŒ"""
    print("=== æµ‹è¯•ç‘å£«å·æ•°æ®é›†é™ç»´å®éªŒ ===")
    
    # å¯¼å…¥å¿…è¦åº“
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn.datasets import make_swiss_roll
    from sklearn.manifold import LocallyLinearEmbedding
    from mpl_toolkits.mplot3d import Axes3D

    # ç”Ÿæˆç‘å£«å·æ•°æ®
    X, color = make_swiss_roll(n_samples=1500, random_state=42)

    # 1. åˆ›å»ºLLEæ¨¡å‹ï¼ˆå¡«ç©º1ï¼šè®¾ç½®n_neighbors=12, n_components=2ï¼‰
    lle = LocallyLinearEmbedding(n_neighbors=12, n_components=2, random_state=42)

    # 2. æ‹Ÿåˆæ¨¡å‹å¹¶è½¬æ¢æ•°æ®ï¼ˆå¡«ç©º2ï¼šè°ƒç”¨fit_transformæ–¹æ³•ï¼‰
    X_lle = lle.fit_transform(X)

    # å¯è§†åŒ–ç»“æœ
    fig = plt.figure(figsize=(12, 6))

    # ç»˜åˆ¶åŸå§‹3Dæ•°æ®
    ax1 = fig.add_subplot(121, projection='3d')
    ax1.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap='viridis')
    ax1.set_title('Original Swiss Roll Data')
    ax1.view_init(azim=120, elev=10)

    # 3. ç»˜åˆ¶LLEé™ç»´å2Dæ•°æ®ï¼ˆå¡«ç©º3ï¼šè¡¥å……X_lleçš„ä¸¤ä¸ªç»´åº¦ï¼‰
    ax2 = fig.add_subplot(122)
    ax2.scatter(X_lle[:, 0], X_lle[:, 1], c=color, cmap='viridis')
    ax2.set_title('LLE Reduced Data (2D)')
    ax2.set_xlabel('Component 1')
    ax2.set_ylabel('Component 2')

    plt.tight_layout()
    plt.savefig('j:\\å®éªŒè®²ä¹‰\\å±€éƒ¨çº¿æ€§åµŒå…¥\\swiss_roll_lle_result.png', dpi=150, bbox_inches='tight')
    plt.show()

    # 4. è¾“å‡ºé‡æ„è¯¯å·®ï¼ˆå¡«ç©º4ï¼šè·å–reconstruction_error_å±æ€§ï¼‰
    print(f"Reconstruction error: {lle.reconstruction_error_:.4f}")
    print("ç‘å£«å·æ•°æ®é›†æµ‹è¯•å®Œæˆï¼\n")
    
    return True

def test_digits_example():
    """æµ‹è¯•æ‰‹å†™æ•°å­—æ•°æ®é›†é™ç»´å®éªŒ"""
    print("=== æµ‹è¯•æ‰‹å†™æ•°å­—æ•°æ®é›†é™ç»´å®éªŒ ===")
    
    # å¯¼å…¥å¿…è¦åº“
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn.datasets import load_digits
    from sklearn.manifold import LocallyLinearEmbedding
    from sklearn.model_selection import train_test_split
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.metrics import accuracy_score

    # åŠ è½½æ‰‹å†™æ•°å­—æ•°æ®é›†
    digits = load_digits()
    X, y = digits.data, digits.target
    print(f"Dataset shape: {X.shape}, Class distribution: {np.bincount(y)}")

    # æ•°æ®é¢„å¤„ç†ï¼šå½’ä¸€åŒ–
    X = X / X.max()

    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )

    # 5. åˆ›å»ºLLEæ¨¡å‹ï¼ˆå¡«ç©º5ï¼šè®¾ç½®n_neighbors=15, n_components=20ï¼‰
    lle = LocallyLinearEmbedding(n_neighbors=15, n_components=20, random_state=42)

    # 6. æ‹Ÿåˆè®­ç»ƒæ•°æ®å¹¶è½¬æ¢ï¼ˆå¡«ç©º6ï¼šè°ƒç”¨fit_transformå’Œtransformæ–¹æ³•ï¼‰
    X_train_lle = lle.fit_transform(X_train)
    X_test_lle = lle.transform(X_test)

    # ä½¿ç”¨KNNè¿›è¡Œåˆ†ç±»ï¼ˆé™ç»´å‰åå¯¹æ¯”ï¼‰
    knn_orig = KNeighborsClassifier(n_neighbors=5)
    knn_orig.fit(X_train, y_train)
    y_pred_orig = knn_orig.predict(X_test)
    acc_orig = accuracy_score(y_test, y_pred_orig)

    # 7. åœ¨é™ç»´æ•°æ®ä¸Šè®­ç»ƒKNNï¼ˆå¡«ç©º7ï¼šä½¿ç”¨X_train_lleè®­ç»ƒï¼‰
    knn_lle = KNeighborsClassifier(n_neighbors=5)
    knn_lle.fit(X_train_lle, y_train)
    y_pred_lle = knn_lle.predict(X_test_lle)
    acc_lle = accuracy_score(y_test, y_pred_lle)

    print(f"Original data accuracy: {acc_orig:.4f}")
    print(f"LLE reduced data accuracy: {acc_lle:.4f}")
    print(f"Feature dimension reduced from {X.shape[1]} to {X_train_lle.shape[1]}")

    # å¯è§†åŒ–é™ç»´ç»“æœ
    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(X_train_lle[:, 0], X_train_lle[:, 1], c=y_train, 
                         cmap=plt.cm.get_cmap('tab10', 10), alpha=0.7)
    plt.colorbar(scatter, ticks=range(10), label='Digit Class')
    plt.title('LLE Visualization of Digits Dataset (2D)')
    plt.xlabel('Component 1')
    plt.ylabel('Component 2')
    plt.savefig('j:\\å®éªŒè®²ä¹‰\\å±€éƒ¨çº¿æ€§åµŒå…¥\\digits_lle_result.png', dpi=150, bbox_inches='tight')
    plt.show()
    
    print("æ‰‹å†™æ•°å­—æ•°æ®é›†æµ‹è¯•å®Œæˆï¼\n")
    return True

def test_image_retrieval_system():
    """æµ‹è¯•å›¾åƒæ£€ç´¢ç³»ç»Ÿ"""
    print("=== æµ‹è¯•å›¾åƒæ£€ç´¢ç³»ç»Ÿ ===")
    
    try:
        # å¯¼å…¥å¿…è¦åº“
        import numpy as np
        import matplotlib.pyplot as plt
        from sklearn.manifold import LocallyLinearEmbedding
        from sklearn.datasets import fetch_olivetti_faces
        from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
        from sklearn.decomposition import PCA
        import time

        # è®¾ç½®éšæœºç§å­ç¡®ä¿ç»“æœå¯é‡ç°
        np.random.seed(42)

        class ImageRetrievalSystem:
            """åŸºäºLLEçš„å›¾åƒæ£€ç´¢ç³»ç»Ÿ"""
            
            def __init__(self, n_neighbors=15, n_components=50):
                self.n_neighbors = n_neighbors
                self.n_components = n_components
                self.lle = LocallyLinearEmbedding(
                    n_neighbors=n_neighbors, 
                    n_components=n_components, 
                    random_state=42
                )
                self.pca = PCA(n_components=n_components, random_state=42)
                self.features_original = None
                self.features_lle = None
                self.features_pca = None
                
            def fit(self, features):
                """è®­ç»ƒé™ç»´æ¨¡å‹"""
                print(f"Training on {features.shape[0]} images with {features.shape[1]} features...")
                
                # ä¿å­˜åŸå§‹ç‰¹å¾
                self.features_original = features
                
                # LLEé™ç»´
                start_time = time.time()
                self.features_lle = self.lle.fit_transform(features)
                lle_time = time.time() - start_time
                
                # PCAé™ç»´ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
                start_time = time.time()
                self.features_pca = self.pca.fit_transform(features)
                pca_time = time.time() - start_time
                
                print(f"LLEé™ç»´æ—¶é—´: {lle_time:.3f}ç§’")
                print(f"PCAé™ç»´æ—¶é—´: {pca_time:.3f}ç§’")
                print(f"LLEé‡æ„è¯¯å·®: {self.lle.reconstruction_error_:.6f}")
                
            def retrieve_images(self, query_idx, method='lle', top_k=5):
                """å›¾åƒæ£€ç´¢"""
                if method == 'lle':
                    features = self.features_lle
                    query_feature = features[query_idx]
                elif method == 'pca':
                    features = self.features_pca
                    query_feature = features[query_idx]
                else:  # original
                    features = self.features_original
                    query_feature = features[query_idx]
                    
                # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
                similarities = cosine_similarity([query_feature], features)[0]
                
                # è·å–top-kç›¸ä¼¼å›¾åƒç´¢å¼•ï¼ˆæ’é™¤æŸ¥è¯¢å›¾åƒæœ¬èº«ï¼‰
                similarities[query_idx] = -1  # æ’é™¤è‡ªèº«
                top_indices = similarities.argsort()[::-1][:top_k]
                
                return top_indices, similarities[top_indices]
            
            def evaluate_retrieval_performance(self, n_queries=10):  # å‡å°‘æŸ¥è¯¢æ•°é‡ä»¥åŠ å¿«æµ‹è¯•
                """è¯„ä¼°æ£€ç´¢æ€§èƒ½"""
                methods = ['original', 'lle', 'pca']
                results = {method: {'times': [], 'similarities': []} for method in methods}
                
                # éšæœºé€‰æ‹©æŸ¥è¯¢å›¾åƒ
                query_indices = np.random.choice(len(self.features_original), n_queries, replace=False)
                
                for query_idx in query_indices:
                    for method in methods:
                        start_time = time.time()
                        top_indices, similarities = self.retrieve_images(query_idx, method, top_k=5)
                        retrieval_time = time.time() - start_time
                        
                        results[method]['times'].append(retrieval_time)
                        results[method]['similarities'].append(np.mean(similarities))
                
                # è®¡ç®—å¹³å‡æ€§èƒ½
                for method in methods:
                    avg_time = np.mean(results[method]['times'])
                    avg_similarity = np.mean(results[method]['similarities'])
                    print(f"{method.upper()} - å¹³å‡æ£€ç´¢æ—¶é—´: {avg_time:.6f}ç§’, å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.4f}")
                    
                return results

        # åŠ è½½Olivettiäººè„¸æ•°æ®é›†
        print("åŠ è½½Olivettiäººè„¸æ•°æ®é›†...")
        faces = fetch_olivetti_faces(shuffle=True, random_state=42)
        X, y = faces.data, faces.target
        
        print(f"æ•°æ®é›†ä¿¡æ¯: {X.shape[0]}å¼ å›¾åƒ, æ¯å¼ {X.shape[1]}ç»´ç‰¹å¾")
        print(f"å…±{len(np.unique(y))}ä¸ªä¸åŒçš„äºº")
        
        # æ•°æ®é¢„å¤„ç†ï¼šæ ‡å‡†åŒ–
        X = (X - X.mean(axis=0)) / (X.std(axis=0) + 1e-8)
        
        # åˆ›å»ºæ£€ç´¢ç³»ç»Ÿ
        retrieval_system = ImageRetrievalSystem(n_neighbors=15, n_components=50)
        
        # è®­ç»ƒæ¨¡å‹
        retrieval_system.fit(X)
        
        # è¯„ä¼°æ€§èƒ½
        print("\n=== æ£€ç´¢æ€§èƒ½è¯„ä¼° ===")
        performance_results = retrieval_system.evaluate_retrieval_performance(n_queries=10)
        
        # ç®€å•çš„å¯è§†åŒ–æµ‹è¯•
        query_idx = 10
        top_indices, similarities = retrieval_system.retrieve_images(query_idx, 'lle', top_k=5)
        print(f"\nLLEæ£€ç´¢ç»“æœ - Top 5 ç›¸ä¼¼åº¦: {similarities}")
        
        print("å›¾åƒæ£€ç´¢ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼\n")
        return True
        
    except Exception as e:
        print(f"å›¾åƒæ£€ç´¢ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•LLEå®éªŒè®²ä¹‰ä¸­çš„æ‰€æœ‰ä»£ç ...\n")
    
    test_results = []
    
    # æµ‹è¯•ç‘å£«å·ç¤ºä¾‹
    try:
        result1 = test_swiss_roll_example()
        test_results.append(("ç‘å£«å·æ•°æ®é›†", result1))
    except Exception as e:
        print(f"ç‘å£«å·æ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        test_results.append(("ç‘å£«å·æ•°æ®é›†", False))
    
    # æµ‹è¯•æ‰‹å†™æ•°å­—ç¤ºä¾‹
    try:
        result2 = test_digits_example()
        test_results.append(("æ‰‹å†™æ•°å­—æ•°æ®é›†", result2))
    except Exception as e:
        print(f"æ‰‹å†™æ•°å­—æ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        test_results.append(("æ‰‹å†™æ•°å­—æ•°æ®é›†", False))
    
    # æµ‹è¯•å›¾åƒæ£€ç´¢ç³»ç»Ÿ
    try:
        result3 = test_image_retrieval_system()
        test_results.append(("å›¾åƒæ£€ç´¢ç³»ç»Ÿ", result3))
    except Exception as e:
        print(f"å›¾åƒæ£€ç´¢ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        test_results.append(("å›¾åƒæ£€ç´¢ç³»ç»Ÿ", False))
    
    # è¾“å‡ºæµ‹è¯•ç»“æœæ€»ç»“
    print("=== æµ‹è¯•ç»“æœæ€»ç»“ ===")
    for test_name, result in test_results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"{test_name}: {status}")
    
    all_passed = all(result for _, result in test_results)
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼ä»£ç å¯ä»¥æ­£å¸¸è¿è¡Œã€‚")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ä»£ç ã€‚")
    
    return all_passed

if __name__ == "__main__":
    main()